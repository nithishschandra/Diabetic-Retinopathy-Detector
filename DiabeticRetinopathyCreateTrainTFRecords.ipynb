{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Diabetic Retinopathy Image Preprocessing and tfrecords creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re, math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "# check TF version (want: 2.3)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = './'\n",
    "\n",
    "FILE_LABELS = os.path.join(BASE_DIR, 'trainLabels.csv')\n",
    "TRAIN_IMAGES_DIR = os.path.join(BASE_DIR, 'train')\n",
    "\n",
    "TFREC_DIR = os.path.join(BASE_DIR, 'tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13_left</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13_right</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15_left</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image  level\n",
       "0   10_left      0\n",
       "1  10_right      0\n",
       "2   13_left      0\n",
       "3  13_right      0\n",
       "4   15_left      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels = pd.read_csv(FILE_LABELS)\n",
    "\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_labels.level.hist(bins = [0,1,2,3,4,5]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "level\n",
       "0    25810\n",
       "1     2443\n",
       "2     5292\n",
       "3      873\n",
       "4      708\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.groupby(['level']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codice preparazione file tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_from_gray(img,tol=7):\n",
    "    if img.ndim ==2:\n",
    "        mask = img>tol\n",
    "        return img[np.ix_(mask.any(1),mask.any(0))]\n",
    "    elif img.ndim==3:\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        mask = gray_img>tol\n",
    "        \n",
    "        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n",
    "        if (check_shape == 0): # image is too dark so that we crop out everything,\n",
    "            return img # return original image\n",
    "        else:\n",
    "            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n",
    "            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n",
    "    \n",
    "            img = np.stack([img1,img2,img3],axis=-1)\n",
    "    \n",
    "        return img\n",
    "\n",
    "def preprocess_image(image, crop=False, blur = False, sigmaX=10):\n",
    "    # CV2 per default tratta le immagini come BGR\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if crop == True:\n",
    "        image = crop_image_from_gray(image)\n",
    "    \n",
    "    image = cv2.resize(image, (IMG_PIXEL, IMG_PIXEL), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    if blur == True:\n",
    "        image = cv2.addWeighted (image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions from TF2 docs\n",
    "def _bytes_feature(value):\n",
    "  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "  if isinstance(value, type(tf.constant(0))):\n",
    "    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "  \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize_example(img, patient_id, side, label):\n",
    "  feature = {\n",
    "      'image': _bytes_feature(img),\n",
    "      'patient_id': _int64_feature(patient_id),\n",
    "      'side': _int64_feature(side),       # 0,1, left,right\n",
    "      'label': _int64_feature(label) # [0, 4]\n",
    "  }\n",
    "  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "  return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Writing TFRecord 1 of 18...\n",
      "# # # # # # # # # # # # # # # # # # # # \n",
      "Elapsed:  697.6  (sec)\n",
      "\n",
      "Writing TFRecord 2 of 18...\n",
      "# # # # # # # # # # # "
     ]
    }
   ],
   "source": [
    "# how many imgs in file\n",
    "SIZE = 2000\n",
    "\n",
    "IMG_PIXEL = 512\n",
    "\n",
    "# dataframe where to take metadata\n",
    "df = df_labels \n",
    "\n",
    "# imgs to process\n",
    "IMGS = df['image'].values\n",
    "\n",
    "CT = len(IMGS)//SIZE + int(len(IMGS)%SIZE!=0)\n",
    "\n",
    "count = 0\n",
    "\n",
    "for j in range(CT):\n",
    "    print(); \n",
    "    print('Writing TFRecord %i of %i...'%(j+1, CT))\n",
    "    \n",
    "    tStart = time.time()\n",
    "    \n",
    "    CT2 = min(SIZE, len(IMGS)-j*SIZE)\n",
    "    \n",
    "    with tf.io.TFRecordWriter(os.path.join(TFREC_DIR, 'train%.2i-%i.tfrec'%(j,CT2))) as writer:\n",
    "        for k in range(CT2):\n",
    "            index = SIZE*j+k\n",
    "            img_path = os.path.join(TRAIN_IMAGES_DIR, df.iloc[index].image) + '.jpeg'\n",
    "            \n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # per default CV2 legge in BGR\n",
    "        \n",
    "            # img = cv2.resize(img, (IMG_PIXEL, IMG_PIXEL), interpolation = cv2.INTER_AREA)\n",
    "            img = preprocess_image(img, crop=True, blur = True, sigmaX=10)\n",
    "            \n",
    "            # potrei cambiare la qualit√† !!! portarla al 100%\n",
    "            img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tobytes()\n",
    "            \n",
    "            name = IMGS[index]\n",
    "            \n",
    "            # get the row from Dataframe\n",
    "            row = df.iloc[index]\n",
    "            \n",
    "            # get patientId\n",
    "            patientID = int(row['image'].split('_')[0])\n",
    "            \n",
    "            # encode side: left = 0, right = 1\n",
    "            if 'left' in row['image']:\n",
    "                side = 0\n",
    "            else:\n",
    "                side = 1\n",
    "            \n",
    "            level = row['level']\n",
    "            \n",
    "            # build the record\n",
    "            # image, patientid, side, label\n",
    "            example = serialize_example(img, patientID, side, level)\n",
    "                \n",
    "            writer.write(example)\n",
    "            \n",
    "            # print progress\n",
    "            if k%100==0: print('#','',end='')\n",
    "                \n",
    "    tEnd = time.time()\n",
    "    \n",
    "    print('')\n",
    "    print('Elapsed: ', round((tEnd - tStart),1), ' (sec)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_FILENAMES = tf.io.gfile.glob(os.path.join(TFREC_DIR,'train*.tfrec'))\n",
    "\n",
    "TRAIN_FILENAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contiamo il totale delle immagini (dai nomi)\n",
    "count_data_items(TRAIN_FILENAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "imSize = 256\n",
    "IMAGE_SIZE= [256,256]\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    # porto a 256x256\n",
    "    # image = tf.image.resize(image, [imSize,imSize])\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        'patient_id' : tf.io.FixedLenFeature([], tf.int64), \n",
    "        'side' : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'label' : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    \n",
    "    image = decode_image(example['image'])\n",
    "    patient_id = example['patient_id']\n",
    "    side = example['side']\n",
    "    label = example['label']\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(filenames):\n",
    "    dataset = load_dataset(filenames, labeled=True)\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = get_training_dataset(TRAIN_FILENAMES)\n",
    "train_dataset = train_dataset.unbatch().batch(20)\n",
    "train_batch = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: reading TFREcords file...\n",
      "Examples of the train data:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Test: reading TFREcords file...')\n",
    "print(\"Examples of the train data:\")\n",
    "\n",
    "print()\n",
    "\n",
    "batch_num = 0\n",
    "\n",
    "for image, label in train_dataset.take(5):\n",
    "    batch_num += 1\n",
    "    print('')\n",
    "    print('Batch num. ', batch_num)\n",
    "    print(\"The image batch size:\", image.numpy().shape)\n",
    "    print(\"Label\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OK, seems OK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
